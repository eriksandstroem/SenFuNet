SETTINGS:
  gpu: True
  experiment_path: /cluster/work/cvl/esandstroem/src/late_fusion_3dconvnet/workspace/fusion # path where the logging is done and the models are saved.
  save_mode: test # make sure this is set to "test" when using test_fusion.py. Other options: ply or tsdf depending on what you want to save
  eval_freq: 1000 # how many global steps before evaluation and saving the model
  log_freq: 500 # how many global steps before logging the training loss
  seed: 52
FUSION_MODEL:
  fixed: True
  output_scale: 1.0
  n_points_tof: 11
  n_tail_points_tof: 9
  n_points_stereo: 11
  n_tail_points_stereo: 9
  confidence: False
  n_empty_space_voting: 10
  with_peek: False
  max_weight: 500
  extraction_strategy: 'nearest_neighbor' # nearest_neighbor or trilinear_interpolation
FEATURE_MODEL:
  w_rgb: False
  w_intensity_gradient: False
  normalize: False
  fixed: False
  n_features: 6
  n_points_tof: 11
  n_tail_points_tof: 9
  n_points_stereo: 11
  n_tail_points_stereo: 9
  use_count: True
  output_scale: 1.0
  n_layers: 2
  activation: torch.nn.ReLU()
  normalization: layer
  depth: True
  resx: 256
  resy: 256
# TRANSLATION_MODEL:
#   fixed: False
#   train_on_border_voxels: False
#   erosion: False
#   neighborhood: 3 # side length of voxel neighborhood cube, needs to be an odd number
#   count: absolute
#   superresolve: False
#   activation: torch.nn.Tanh()
#   occ_head: True
#   output_scale: 1.0
#   mode: float
ROUTING_MODEL:
  contraction: 64
  depth: 1
  n_output_channels: 2
  normalization: True
FILTERING_MODEL:
  fuse_sensors: True
  w_features: False
  output_scale: 0.12
  chunk_size: 64 # this size determines the size of the window used during training and testing that is fed to the 3D convnet
  fixed: False
  tanh_weight: True
  activation: torch.nn.ReLU()
  nbr_groups: 2
  grouping_strategy: 'absolute'
  network_depth: 1
  train_on_border_voxels: False
  erosion: False # faq hur blir det mer erosion med neighborhood 7 som input...? I need to make the tail subtraction
  # more aggressive. Now it is 2, but I need to make it 3. The image erosion should be fine since it is 6 now. But what 
  # about during validation? I would ideally have to erode 3 times in order to get rid of those outliers... I cannot afford that.
  # The only solutions is to make the tail longer and pad more if that is required or hope that the filtering network can handle it with 
  # only 1 erosion step. Needs more investigation. Since we extract a larger grid and predict for a smaller one, we actually will not include the tsdf 
  # values of those uninit voxels at the border so we are still safe with one erosion, but it might make the predictions fukked, I am not sure.
LOSS:
  gt_loss: False
  outlier_focus: False
  focus_threshold: 0.05
  focus_outliers_weight: 10 # not used now, needs to be made to tensor torch.tensor([10, 1])
  l1_weight: 1.0 # not used now
  l2_weight: 0.0 # not used now
  grid_weight: 6
  grid_weight_gt: 6
  occ_weight: 0.01
  outlier_loss: False
  outlier_weight: 0.5
  feature_regularization: True
  feat_reg_weight: 0.05
TRAINING:
  reset_strategy: False # True or False 
  reset_prob: 0.01 # in percent (used if reset_strategy: True)
  pretraining: True
  pretraining_fusion_tof_model_path: /cluster/work/cvl/esandstroem/src/late_fusion/workspace/fusion/210426-153135/model/best_tof.pth.tar # if path exists, will load these weights at the start of training
  pretraining_fusion_stereo_model_path: /cluster/work/cvl/esandstroem/src/late_fusion/workspace/fusion/210426-153135/model/best_stereo.pth.tar
  routing_stereo_model_path: /home/esandstroem/scratch-second/opportunistic_3d_capture/Erik_3D_Reconstruction_Project/src/late_fusion/workspace/routing/stereo/model/best.pth.tar
  routing_tof_model_path: /home/esandstroem/scratch-second/opportunistic_3d_capture/Erik_3D_Reconstruction_Project/src/late_fusion/workspace/routing/tof/model/best.pth.tar
  train_batch_size: 1
  train_shuffle: False
  val_batch_size: 1
  val_shuffle: False
  n_epochs: 1000
  clipping: True
  outlier_filter_val: 0
TESTING:
  test_batch_size: 1
  test_shuffle: False
  pretrain_filtering_net: False
  fusion_model_path: /cluster/work/cvl/esandstroem/src/late_fusion_3dconvnet/workspace/fusion/210429-095017/model/best.pth.tar # 210330-231415
  weight_thresholds: [0.0]
ROUTING:
  do: False
  threshold: 0.0 # note that confidence threshold for multidepth routingNet is 0.25
  threshold_mono: 0.0
  threshold_stereo: 0.0
  threshold_tof: 0.0
OPTIMIZATION:
  scheduler:
    step_size_filtering: 500
    step_size_fusion: 100
    gamma_filtering: 0.1
    gamma_fusion: 0.5
  lr_filtering: 1.e-04
  lr_fusion: 1.e-04
  rho: 0.95
  eps: 1.e-09
  momentum: 0.9
  weight_decay: 0.01
  accumulate: True
  accumulation_steps: 10 # note that this is normally 8
  alternate: False
  alternate_steps: 5
DATA:
  sampling_density_stereo: 1
  sampling_density_tof: 1
  mask_stereo_height: 35 # in pixels (achieves fov 71.11). Together with the width mask this gives the same relationship between the height and width fov
  # compared to the color camera of the azure kinect
  mask_stereo_width: 10 # in pixels (achieves fov 84.32)
  mask_tof_height: 52 # 52 # in pixels. Note that this value depends on the resolution of the image. With resolution 256 this would be 52
  mask_tof_width: 35 # 35 # in pixels. With resolution 256 this would be 35
  pad: 0
  min_depth_stereo: 0.5
  max_depth_stereo: 2.5
  min_depth_tof: 0.5
  max_depth_tof: 3.86
  fusion_strategy: two_fusionNet # routingNet or fusionNet or three_fusionNet or fusionNet_conditioned (only applicable when DATA.input = 'multidepth')
  data_load_strategy: max_depth_diversity # max_depth_diversity, hybrid (Note: if X_shuffle is true, this option serves no purpose)
  load_scenes_at_once: 1
  intensity_grad: False # weather to load the grayscale image and its gradient and feed to the routing network
  root_dir: /cluster/work/cvl/esandstroem/data/replica/manual #TMPDIR #/home/esandstroem/scratch-second/euler_work/data/replica/manual #training on data from work folder or on local scratch of compute node
  dataset: Replica
  input: multidepth # mono_depth, stereo_depth, tof_depth, depth_gt, multidepth
  target: depth_gt
  resx_stereo: 256
  resy_stereo: 256
  resx_tof: 256 # a tof camera has typically half the resolution of an rgb camera
  resy_tof: 256
  train_scene_list: /cluster/project/cvl/esandstroem/src/late_fusion_3dconvnet/lists/replica/test_office_1.txt
  val_scene_list: /cluster/project/cvl/esandstroem/src/late_fusion_3dconvnet/lists/replica/test_office_1.txt
  test_scene_list: /cluster/project/cvl/esandstroem/src/late_fusion_3dconvnet/lists/replica/test_office_1.txt # /home/esandstroem/scratch-second/euler_project/src/late_fusion_w_featurefusion/lists/replica/test_office_1.txt #
  transform: ToTensor()
  init_value: 0.0 # init value of tsdf grids
  trunc_value: 0.1 # truncation distance
  truncation_strategy: standard # standard, artificial or none
